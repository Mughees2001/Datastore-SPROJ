{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Our Approach - Single Queue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from threading import Thread\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "# project_directory = Path.cwd().parent / 'SingleQueue'\n",
        "# Add 'SingleQueue' directory to sys.path to access its modules\n",
        "# sys.path.insert(0, str(project_directory))\n",
        "# Now you can import Client and Server\n",
        "# from client import Client\n",
        "# from server import Server\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_benchmark(server,client, num_keys, num_iterations=5):\n",
        "    \"\"\"\n",
        "    Run the benchmark for PUT and GET operations on the custom server via Client.\n",
        "    \n",
        "    :param client: The client instance connected to the server.\n",
        "    :param num_keys: The number of keys to test with.\n",
        "    :param num_iterations: The number of times to run the benchmark.\n",
        "    :return: A tuple of (average put time, average get time).\n",
        "    \"\"\"\n",
        "    put_times = []\n",
        "    get_times = []\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        server.reset_state()  # Assuming this method is implemented in the client\n",
        "\n",
        "        keys = [f'key{i}' for i in range(1, num_keys + 1)]\n",
        "        \n",
        "        # Reset the server state here if possible, e.g., client.reset_server()\n",
        "        \n",
        "        # Benchmark PUT operation\n",
        "        start_time = time.perf_counter()\n",
        "        for key in keys:\n",
        "            client.put(key, b'value')\n",
        "        put_times.append(time.perf_counter() - start_time)\n",
        "\n",
        "        # Benchmark GET operation\n",
        "        start_time = time.perf_counter()\n",
        "        for key in keys:\n",
        "            client.get(key)\n",
        "        get_times.append(time.perf_counter() - start_time)\n",
        "\n",
        "    # Calculate average times\n",
        "    avg_put_time = sum(put_times) / len(put_times)\n",
        "    avg_get_time = sum(get_times) / len(get_times)\n",
        "\n",
        "    return avg_put_time, avg_get_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Starting Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def start_server(server_instance):\n",
        "    server_instance.run()\n",
        "\n",
        "# Start the server thread\n",
        "server = Server()\n",
        "server_thread = Thread(target=start_server, args=(server,))\n",
        "server_thread.daemon = True\n",
        "server_thread.start()\n",
        "\n",
        "# Ensure the server has time to start up\n",
        "time.sleep(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Client doing PUT/GET requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Client\n",
        "client = Client()  # Connect to the server here\n",
        "\n",
        "# Range of number of keys\n",
        "num_keys_range = range(100, 10001, 1000)\n",
        "\n",
        "# Lists for average times\n",
        "avg_put_times = []\n",
        "avg_get_times = []\n",
        "\n",
        "# Run the benchmark\n",
        "for num_keys in num_keys_range:\n",
        "    avg_put_time, avg_get_time = run_benchmark(server,client, num_keys)\n",
        "    avg_put_times.append(avg_put_time)\n",
        "    avg_get_times.append(avg_get_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(num_keys_range, avg_put_times, label='PUT', color='blue')\n",
        "plt.plot(num_keys_range, avg_get_times, label='GET', color='orange')\n",
        "plt.xlabel('Number of Keys')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.legend()\n",
        "plt.title('Custom Server PUT and GET Benchmark via Client')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Redis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import redis\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_benchmark(redis_client, num_keys, num_iterations=1):\n",
        "    \"\"\"\n",
        "    Run the benchmark for PUT (SET) and GET operations on Redis.\n",
        "    \n",
        "    :param redis_client: The Redis client instance.\n",
        "    :param num_keys: The number of keys to test with.\n",
        "    :param num_iterations: The number of times to run the benchmark.\n",
        "    :return: A tuple of (average put time, average get time).\n",
        "    \"\"\"\n",
        "    put_times = []\n",
        "    get_times = []\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        # Generate keys and values\n",
        "        keys = [f'key{i}' for i in range(1, num_keys + 1)]\n",
        "        values = ['value' * (i % 100 + 1) for i in range(1, num_keys + 1)]  # Vary value sizes\n",
        "\n",
        "        # Clear the database before PUT operations\n",
        "        redis_client.flushdb()\n",
        "        time.sleep(1)  # Allow some time for the flush to complete\n",
        "\n",
        "        # Benchmark PUT (SET) operation\n",
        "        start_time = time.perf_counter()\n",
        "        for key, value in zip(keys, values):\n",
        "            redis_client.set(key, value)\n",
        "        put_times.append(time.perf_counter() - start_time)\n",
        "\n",
        "        # Benchmark GET operation\n",
        "        start_time = time.perf_counter()\n",
        "        for key in keys:\n",
        "            redis_client.get(key)\n",
        "        get_times.append(time.perf_counter() - start_time)\n",
        "\n",
        "    # Calculate average times\n",
        "    avg_put_time = sum(put_times) / len(put_times)\n",
        "    avg_get_time = sum(get_times) / len(get_times)\n",
        "\n",
        "    return avg_put_time, avg_get_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Redis client\n",
        "redis_client = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
        "\n",
        "# Range of number of keys\n",
        "num_keys_range = range(100, 10001, 1000)\n",
        "\n",
        "# Lists for average times\n",
        "avg_put_times = []\n",
        "avg_get_times = []\n",
        "\n",
        "# Run the benchmark\n",
        "# for num_keys in num_keys_range:\n",
        "avg_put_time, avg_get_time = run_benchmark(redis_client, 1000)\n",
        "    # avg_put_times.append(avg_put_time)\n",
        "    # avg_get_times.append(avg_get_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(num_keys_range, avg_put_times, label='PUT (SET)', color='blue')\n",
        "plt.plot(num_keys_range, avg_get_times, label='GET', color='orange')\n",
        "plt.xlabel('Number of Keys')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.legend()\n",
        "plt.title('Redis PUT (SET) and GET Benchmark')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Memcache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install python-memcached"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import memcache\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_benchmark(memcached_client, num_keys, num_iterations=5):\n",
        "    \"\"\"\n",
        "    Run the benchmark for PUT and GET operations on Memcached.\n",
        "    \n",
        "    :param memcached_client: The Memcached client instance.\n",
        "    :param num_keys: The number of keys to test with.\n",
        "    :param num_iterations: The number of times to run the benchmark.\n",
        "    :return: A tuple of (average put time, average get time).\n",
        "    \"\"\"\n",
        "    put_times = []\n",
        "    get_times = []\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        # Generate keys\n",
        "        keys = [f'key{i}' for i in range(1, num_keys + 1)]\n",
        "        values = ['value' * (i % 100 + 1) for i in range(1, num_keys + 1)]  # Vary value sizes\n",
        "\n",
        "        # Clear the cache before PUT operations\n",
        "        memcached_client.flush_all()\n",
        "        time.sleep(1)  # Allow some time for the flush to complete\n",
        "\n",
        "        # Benchmark PUT operation\n",
        "        start_time = time.perf_counter()\n",
        "        for key, value in zip(keys, values):\n",
        "            memcached_client.set(key, value)\n",
        "        put_times.append(time.perf_counter() - start_time)\n",
        "\n",
        "        # Benchmark GET operation\n",
        "        start_time = time.perf_counter()\n",
        "        for key in keys:\n",
        "            memcached_client.get(key)\n",
        "        get_times.append(time.perf_counter() - start_time)\n",
        "\n",
        "    # Calculate average times\n",
        "    avg_put_time = sum(put_times) / len(put_times)\n",
        "    avg_get_time = sum(get_times) / len(get_times)\n",
        "\n",
        "    return avg_put_time, avg_get_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Memcached client\n",
        "memcached_client = memcache.Client(['localhost:11211'])\n",
        "\n",
        "# Range of number of keys\n",
        "num_keys_range = range(100, 10001, 1000)\n",
        "\n",
        "# Lists for average times\n",
        "avg_put_times = []\n",
        "avg_get_times = []\n",
        "\n",
        "# Run the benchmark\n",
        "for num_keys in num_keys_range:\n",
        "    avg_put_time, avg_get_time = run_benchmark(memcached_client, num_keys)\n",
        "    avg_put_times.append(avg_put_time)\n",
        "    avg_get_times.append(avg_get_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(num_keys_range, avg_put_times, label='PUT', color='blue')\n",
        "plt.plot(num_keys_range, avg_get_times, label='GET', color='orange')\n",
        "plt.xlabel('Number of Keys')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.legend()\n",
        "plt.title('Memcached PUT and GET Benchmark')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Zookeeper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install kazoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import logging\n",
        "from kazoo.client import KazooClient\n",
        "from kazoo.exceptions import NodeExistsError, NoNodeError\n",
        "import matplotlib.pyplot as plt\n",
        "from threading import Thread\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_benchmark(zk, num_znodes, num_iterations=3):\n",
        "    # Ensure the parent path exists\n",
        "    zk.ensure_path('/test')\n",
        "    \n",
        "    # Prepare znode paths\n",
        "    znodes = [f'/test/znode{i}' for i in range(num_znodes)]\n",
        "    \n",
        "    # Warm-up phase: Ensure all nodes are created for the warm-up\n",
        "    for znode in znodes:\n",
        "        try:\n",
        "            zk.create(znode, b'value', ephemeral=True)\n",
        "        except NodeExistsError:\n",
        "            pass  # Node already exists, continue\n",
        "\n",
        "    # Warm-up GET operations: Get each node to ensure they're in the cache\n",
        "    for znode in znodes:\n",
        "        try:\n",
        "            zk.get(znode)\n",
        "        except NoNodeError:\n",
        "            pass  # Node may have been deleted, continue\n",
        "\n",
        "    # PUT Benchmark\n",
        "    put_times = []\n",
        "    for _ in range(num_iterations):\n",
        "        start_time = time.perf_counter()\n",
        "        for znode in znodes:\n",
        "            try:\n",
        "                zk.create(znode, b'value', ephemeral=True)\n",
        "            except NodeExistsError:\n",
        "                pass  # Node already exists, continue\n",
        "        end_time = time.perf_counter()\n",
        "        put_times.append(end_time - start_time)\n",
        "\n",
        "    # Ensure nodes exist for GET benchmark\n",
        "    for znode in znodes:\n",
        "        try:\n",
        "            zk.create(znode, b'value', ephemeral=True)\n",
        "        except NodeExistsError:\n",
        "            pass  # Node already exists, continue\n",
        "\n",
        "    # GET Benchmark\n",
        "    get_times = []\n",
        "    for _ in range(num_iterations):\n",
        "        start_time = time.perf_counter()\n",
        "        for znode in znodes:\n",
        "            zk.get(znode)\n",
        "        end_time = time.perf_counter()\n",
        "        get_times.append(end_time - start_time)\n",
        "\n",
        "    # Cleanup after benchmark\n",
        "    for znode in znodes:\n",
        "        try:\n",
        "            zk.delete(znode)\n",
        "        except NoNodeError:\n",
        "            pass  # Node may have been deleted, continue\n",
        "        \n",
        "    avg_put_time = sum(put_times) / len(put_times)\n",
        "    avg_get_time = sum(get_times) / len(get_times)\n",
        "\n",
        "    return avg_put_time, avg_get_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize a connection to the ZooKeeper server\n",
        "zk = KazooClient(hosts='localhost:2181')\n",
        "zk.start()\n",
        "\n",
        "# Range of number of znodes to use for the benchmark\n",
        "num_znodes_range = range(100, 10001, 1000)\n",
        "\n",
        "# Lists to store the average execution times for PUT and GET operations\n",
        "avg_put_times = []\n",
        "avg_get_times = []\n",
        "\n",
        "try:\n",
        "    # Benchmark for different numbers of znodes\n",
        "    for num_znodes in num_znodes_range:\n",
        "        avg_put_time, avg_get_time  = run_benchmark(zk, num_znodes, num_iterations=3)\n",
        "        avg_put_times.append(avg_put_time)\n",
        "        avg_get_times.append(avg_get_time)\n",
        "except Exception as e:\n",
        "    logging.error(\"An error occurred during benchmarking: %s\", e, exc_info=True)\n",
        "finally:\n",
        "    # Close the connection to the ZooKeeper server\n",
        "    zk.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the graph\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(num_znodes_range, avg_put_times, label='PUT Operation Time')\n",
        "plt.plot(num_znodes_range, avg_get_times, label='GET Operation Time')\n",
        "plt.xlabel('Number of Znodes')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.title('ZooKeeper Benchmark: PUT vs GET Operations')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can think of Znodes in Apache ZooKeeper as key-value pairs. Each Znode has a path, which acts as the key, and can store a small amount of data, which acts as the value. This key-value pair mechanism is how ZooKeeper maintains its data hierarchy.\n",
        "\n",
        " Here's an analogy: if you consider ZooKeeper as a distributed, highly available filesystem or directory service, then the Znodes are like files and directories in this system. Just like files/directories have names and can contain data (or other files/directories), Znodes have paths and can contain data (or other Znodes). The key (the Znode's path) is unique and is used to locate and manipulate the value (the data stored in the Znode).\n",
        "\n",
        "In the provided code, the term \"number of Znodes\" refers to the quantity of these key-value pairs that the benchmark script will handle. It creates a specified number of Znodes (num_znodes) and performs operations on them to evaluate performance characteristics such as latency or throughput for create (PUT) and read (GET) operations within the ZooKeeper ensemble."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
